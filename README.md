# CamOnDagsterDbt

A containerized data engineering project combining [Dagster](https://dagster.io/), [dbt](https://www.getdbt.com/), and [DLT](https://docs.dltHub.com/) to orchestrate, transform, and manage modern data workflows. It uses [MotherDuck](https://motherduck.com/) as the data warehouse with serverless compute. 

## ğŸ§± Project Structure

<details>

<summary><strong>ğŸ“ (click to expand)</strong></summary>

```text
CamOnDagsterDbt/
â”œâ”€â”€ cam_on_dagster_dbt/           # Dagster jobs, assets, schedules, sensors, and definitions
â”‚   â”œâ”€â”€ assets/                   # All asset definitions grouped by data source
â”‚   â”œâ”€â”€ jobs/                     # Dagster job definitions
â”‚   â”œâ”€â”€ schedules.py              # Dagster schedules
â”‚   â”œâ”€â”€ sensors.py                # Dagster sensors
â”‚   â”œâ”€â”€ definitions.py            # Central Dagster Definitions object
â”‚   â””â”€â”€ __init__.py               # Package initializer
â”œâ”€â”€ dbt/                          # dbt models and configs
â”‚   â”œâ”€â”€ models/                   # dbt models
â”‚   â”œâ”€â”€ macros/                   # Custom macros
â”‚   â”œâ”€â”€ dbt_project.yml           # dbt project configuration
â”‚   â””â”€â”€ profiles.yml              # dbt profile (excluded from git)
â”œâ”€â”€ .devcontainer/                # Dev container setup
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ devcontainer.json
â”œâ”€â”€ .github/workflows/            # GitHub Actions CI workflows
â”‚   â”œâ”€â”€ docs.yml                  # Auto Generate DBT Docs
â”‚   â””â”€â”€ ci.yml                    # Automatic CI, builds when changes occur to dbt
â”œâ”€â”€ docker-compose.yml            # Main Docker Compose file
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ workspace.yaml                # Dagster workspace configuration
â”œâ”€â”€ dagster.yaml                  # Dagster project configuration
â””â”€â”€ README.md                     # Project documentation
```

</details>


### âš™ï¸ Stack

- ğŸ”„ Dagster for workflow orchestration and asset management

- ğŸ“Š dbt for data modeling and transformations

- âš™ï¸ Data Load Tool (DLT) for incremental pipeline automation

- ğŸ¦† Mother Duck for cloud analytics database

- âœ”ï¸ Great Expectations for data testing and validation

### Features

- Multi-source data ingestion pipelines: Google Sheets, TheCocktailDB, OpenLibrary, Rick and Morty API  
- Modular asset definitions and jobs for maintainability  
- Configured schedules and sensors to automate pipeline runs  
- Centralized definitions to easily manage asset and job dependencies  
- Integration of Great Expectations for data quality validation  
- Environment configurations prepared for local and containerized execution  

### MotherDuck Migration and Future Orchestration with Dagster Cloud

The project has recently migrated from local DuckDB to MotherDuck, a cloud-native SQL lakehouse platform, to leverage scalable and performant data warehousing capabilities. This migration positions the project to benefit from a managed, serverless infrastructure that simplifies data storage and query execution.

Additionally, there are plans to implement Dagster Cloud for orchestration, which will provide a robust, cloud-based workflow management system. This will enable scalable scheduling, monitoring, and observability of data pipelines, complementing the move to MotherDuck.

This approach ensures the project is future-proofed with a fully managed, cloud-first data stack, improving reliability, scalability, and ease of maintenance while retaining infrastructure-as-code best practices for smooth deployment and governance.

### Next Steps
 
- Enhance data quality checks with Great Expectations integration  
- Expand pipeline coverage with additional APIs and datasets

